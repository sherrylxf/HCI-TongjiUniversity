# 智能聊天机器人

> 同济 用户交互设计课程

- 本项目是一个基于 Python + Gradio 构建的本地可视化多模型聊天系统。
- 支持调用 **同济大学 DeepSeek-R1** 、 **智谱 AI GLM-4** 、 **Qwen 通义千问** 三种大语言模型。
- 用户可在网页界面上进行 **基础对话** 、 **多轮对话** ，并 **记录历史对话** 。


## 项目特点

- 支持 DeepSeek-R1 、 GLM-4 、Qwen 模型
- 多轮对话上下文管理
- 对话历史记录保存与读取
- 友好的 Gradio 可视化界面

## 项目结构

```
├── main.py              # 主程序，Gradio 界面与交互逻辑
├── llm_api.py           # 模型调用封装，包括 DeepSeek 和 GLM 的 API
├── requirements.txt     # 所需依赖列表
├── README.md            # 介绍本项目及使用方法
```

## 项目搭建指南（ Python 3.13 ）

### 1. 下载并解压项目文件

请先下载项目压缩包 `LLMApp.zip`，然后解压至本地目录：

```bash
unzip LLMApp.zip
cd LLMApp
```

### 2. 安装项目依赖

建议在虚拟环境中进行安装，以避免环境冲突：

```bash
# 安装依赖
pip install -r requirements.txt
```

### 3. 启动项目

运行主程序：

```bash
python main.py
```

启动成功后，终端会输出本地访问地址。复制该地址，在浏览器中打开即可使用聊天机器人。


## 使用方法

1. **选择模型**：在下拉框中选择 DeepSeek-R1 或 GLM-4 或 Qwen 。
2. **开始对话**：在文本框中输入问题，回车即可开始与大模型的交流。
3. **保存对话**：可输入对话名称并点击「保存对话」按钮，记录本轮对话历史。
4. **读取对话**：通过「选择历史记录对话」下拉菜单读取任意已保存的对话。
5. **清空对话**：点击「清空当前对话」按钮，可开始新的对话。

## 注意事项

- **同济大学 DeepSeek-R1** API 服务仅限校园网（校外通过 VPN ）访问。
- 使用本项目服务，请勿连接国外 VPN ，否则可能出现 **接口调用异常** 的问题。


## 许可证

此项目仅用于学习与研究用途，API 调用请遵守对应平台的使用条款。
